{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import mapstreet data \n",
    "\n",
    "mapstreet = pd.read_csv(\"src_data\\GISMAPSTREET.txt\", sep=\"|\", header=None, skip_blank_lines=True,\n",
    "names=[\"MINORGRIDNAME\", \"STREETNAME\", \"ROADDIRECTIONPREFIXCD\", \"ROADNAME\", \"ROADTYPESUFFIXCD\", \"ROADDIRECTIONSUFFIXCD\", \"ZIPCD\", \"RIGHTZIPCD\", \"LOWADDRESSRANGEVALUE\", \"HIGHADDRESSRANGEVALUE\", \"TOWNSHIPNAME\", \"MUNICIPALITYNAME\", \"NUMCENTERLINES\", \"INTERSECTINGLENGTH\", \"GEOM_WKT\"])\n",
    "\n",
    "print(mapstreet.columns)\n",
    "\n",
    "# mapstreet.dropna(inplace=True)\n",
    "# mapstreet.drop_duplicates(keep='first', inplace=True)\n",
    "mapstreet.drop(columns=[\"ROADDIRECTIONPREFIXCD\", \"ROADNAME\", \"ROADTYPESUFFIXCD\", \"ROADDIRECTIONSUFFIXCD\", \"RIGHTZIPCD\", \"LOWADDRESSRANGEVALUE\", \"HIGHADDRESSRANGEVALUE\", \"TOWNSHIPNAME\"], inplace=True)\n",
    "\n",
    "# dropped_cols = mapstreet.drop(columns=[\"ROADDIRECTIONPREFIXCD\", \"ROADNAME\", \"ROADTYPESUFFIXCD\", \"ROADDIRECTIONSUFFIXCD\", \"RIGHTZIPCD\", \"LOWADDRESSRANGEVALUE\", \"HIGHADDRESSRANGEVALUE\", \"TOWNSHIPNAME\"])\n",
    "\n",
    "# mapstreet = mapstreet.drop(columns=[\"ROADDIRECTIONPREFIXCD\", \"ROADNAME\", \"ROADTYPESUFFIXCD\", \"ROADDIRECTIONSUFFIXCD\", \"RIGHTZIPCD\", \"LOWADDRESSRANGEVALUE\", \"HIGHADDRESSRANGEVALUE\", \"TOWNSHIPNAME\"])\n",
    "# mapstreet.fillna(\"\", inplace=True)\n",
    "\n",
    "# print(dropped_cols)\n",
    "print(mapstreet)\n",
    "mapstreet.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can only map lines with WKT coordinates. Drop all rows which have no value in GEO_WKT\n",
    "mapstreet.dropna(subset=['GEOM_WKT'], how='all', inplace=True)\n",
    "print(mapstreet)\n",
    "mapstreet.to_csv(r'./test_data/mapstreet-test.csv', header=True, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consequence = pd.read_csv(\"src_data\\Street Consequence - Sheet1.csv\", sep=\",\", header=None, skip_blank_lines=True,\n",
    "names=[\"STATE\", \"MUNICIPALITY\", \"STREETNAME\", \"MINORGRIDNAME\", \"CONSEQUENCE\"])\n",
    "\n",
    "consequence.dropna(inplace=True)\n",
    "print(consequence)\n",
    "# consequence.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(consequence, mapstreet, on=\"STREETNAME\")\n",
    "\n",
    "# merged_df.dropna(axis=1, inplace=True)\n",
    "# merged_df.dropna(axis=0, inplace=True)\n",
    "# merged_df.drop(columns=[\"MINORGRIDNAME_y\", \"ROADDIRECTIONPREFIXCD\", \"ROADNAME\", \"ROADTYPESUFFIXCD\", \"ROADDIRECTIONSUFFIXCD\", \"LEFTZIPCD\", \"RIGHTZIPCD\", \"LOWADDRESSRANGEVALUE\", \"HIGHADDRESSRANGEVALUE\", \"TOWNSHIPNAME\", \"MUNICIPALITYNAME\"], inplace=True)\n",
    "merged_df.rename(columns={\"MINORGRIDNAME_x\" : \"MINORGRIDNAME\"}, inplace=True)\n",
    "\n",
    "print(merged_df)\n",
    "merged_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(r'./test_data/combined_test.csv', header=True, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_small = merged_df.drop(columns=[\"STATE\", \"MUNICIPALITY\", \"MINORGRIDNAME_y\", \"ZIPCD\", \"MUNICIPALITYNAME\", \"NUMCENTERLINES\", \"INTERSECTINGLENGTH\"])\n",
    "merged_small.drop(index=0, inplace=True)\n",
    "merged_small.dropna(subset=['GEOM_WKT', \"CONSEQUENCE\"], how='all', inplace=True)\n",
    "merged_small.drop_duplicates(inplace=True)\n",
    "\n",
    "print(merged_small)\n",
    "merged_small.to_csv(r'./test_data/combined_test.csv', header=True, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_rows = merged_small.tail(n=18)\n",
    "print(max(merged_small['CONSEQUENCE']))\n",
    "print(min(merged_small['CONSEQUENCE']))\n",
    "\n",
    "merged_small.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = []\n",
    "\n",
    "for index, row in merged_small.iterrows():\n",
    "    \n",
    "    # Initialize list of coordinate pairs for the row\n",
    "    if type(row['GEOM_WKT']) == str:\n",
    "\n",
    "        if row['GEOM_WKT'].startswith('LINESTRING'):\n",
    "            # Get coordinates for a line string\n",
    "            coordinates_str = re.findall('\\(([^)]+)', row['GEOM_WKT'])[0]\n",
    "            coordinates_list = coordinates_str.split(\",\")\n",
    "            \n",
    "            linestring_list_of_coord_pairs = []\n",
    "            for coordinate_pair in coordinates_list:\n",
    "                float_pair = [float(val) for val in coordinate_pair.split()]\n",
    "                linestring_list_of_coord_pairs.append(float_pair)\n",
    "\n",
    "            if linestring_list_of_coord_pairs:\n",
    "                # create a json block for the linestring feature with coordinates and properties\n",
    "                feature =  { \n",
    "                    \"type\": \"Feature\",\n",
    "                    \"geometry\": {\n",
    "                        \"type\": \"LineString\",\n",
    "                        \"coordinates\": linestring_list_of_coord_pairs \n",
    "                        },\n",
    "                    \"properties\": {\n",
    "                        \"STREETNAME\": row['STREETNAME'],\n",
    "                        \"MINORGRIDNAME\": row['MINORGRIDNAME'],\n",
    "                        \"CONSEQUENCE\": float(row['CONSEQUENCE'])\n",
    "                        }\n",
    "                    }\n",
    "                features_list.append(feature)\n",
    "                        \n",
    "\n",
    "        elif row['GEOM_WKT'].startswith('MULTILINESTRING'):\n",
    "            # Get coordinates for a multi line string\n",
    "            # remove leading parenthesis to make this regex happy\n",
    "            mulitline_coordinates = row['GEOM_WKT'].replace(\"MULTILINESTRING (\", \"\")\n",
    "            coordinates_lines = re.findall('\\(([^)]+)', mulitline_coordinates)\n",
    "            multiline_string_list = []\n",
    "            \n",
    "            for line in coordinates_lines:\n",
    "                line_split = line.split(\",\")\n",
    "\n",
    "                # temporary list to hold list of coordinates for a single line, will be contained in final list of lists\n",
    "                coord_line_temp = []\n",
    "                for coordinate_pair in line_split:\n",
    "                    float_pair = [float(val) for val in coordinate_pair.split()]\n",
    "                    coord_line_temp.append(float_pair)\n",
    "                multiline_string_list.append(coord_line_temp)\n",
    "\n",
    "                \n",
    "            if multiline_string_list:\n",
    "                # confirm that there is a list of coordinate lines\n",
    "\n",
    "                # create a json block for the multilinestring feature with coordinates and properties\n",
    "                feature =  { \n",
    "                    \"type\": \"Feature\",\n",
    "                    \"geometry\": {\n",
    "                        \"type\": \"MultiLineString\",\n",
    "                        \"coordinates\": multiline_string_list \n",
    "                        },\n",
    "                    \"properties\": {\n",
    "                        \"STREETNAME\": row['STREETNAME'],\n",
    "                        \"MINORGRIDNAME\": row['MINORGRIDNAME'],\n",
    "                        \"CONSEQUENCE\": float(row['CONSEQUENCE'])\n",
    "                        }\n",
    "                    }\n",
    "                features_list.append(feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geometries = {\n",
    "    'type': 'FeatureCollection',\n",
    "    'features': features_list,\n",
    "    }\n",
    "\n",
    "\n",
    "with open(\"test_data/allen-co-pipes.json\", \"w\") as write_file:\n",
    "    json.dump(geometries, write_file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_str = \"inside one (inside two), (another two) )\"\n",
    "\n",
    "coordinates_lines = re.findall('\\(([^)]+)', test_str)\n",
    "# coordinates_str = coordinates_str.replace(\",\", \"\")\n",
    "print(coordinates_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # if coord_list_of_list:\n",
    "    #     # print('we have coordinates')\n",
    "\n",
    "    #     for long, lat in coord_list_of_list:\n",
    "    #         # print(long, ', ', lat)\n",
    "\n",
    "    #         feature =  { \n",
    "    #             \"type\": \"Feature\",\n",
    "    #             \"geometry\": {\n",
    "    #                 \"type\": \"LineString\",\n",
    "    #                 \"coordinates\": [\n",
    "    #                 [102.0, 0.0], [103.0, 1.0], [104.0, 0.0], [105.0, 1.0]\n",
    "    #                 ]\n",
    "    #                 },\n",
    "    #             \"properties\": {\n",
    "    #                 \"prop0\": \"value0\",\n",
    "    #                 \"prop1\": 0.0\n",
    "    #                 }\n",
    "    #             }\n",
    "\n",
    "            # for longs,lats in LongLatList\n",
    "            #     poly = {\n",
    "            #         'type': 'Polygon',\n",
    "            #         'coordinates': [[lon,lat] for lon,lat in zip(longs,lats) ]\n",
    "            #     }\n",
    "            #     geos.append(poly)\n",
    "\n",
    "            # geometries = {\n",
    "            #     'type': 'FeatureCollection',\n",
    "            #     'features': geos,\n",
    "            # }\n",
    "\n",
    "            # geo_str = json.dumps(geometries)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "13eb0af71620a846e484681143862ad0a4deab6cadfc353264e5c14897c11035"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
